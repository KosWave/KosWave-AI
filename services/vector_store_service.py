"""Vector store service for managing ChromaDB"""
import json
import os
from typing import List, Tuple
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document
from config import Config
from typing import List, Dict


class VectorStoreService:
    """ChromaDB ë²¡í„° ìŠ¤í† ì–´ ê´€ë¦¬ ì„œë¹„ìŠ¤ (Singleton)"""
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(VectorStoreService, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        """Initialize vector store (only once)"""
        if VectorStoreService._initialized:
            return
            
        print("ğŸ”§ Vector Store ì´ˆê¸°í™” ì¤‘...")
        
        # Embeddings ì´ˆê¸°í™”
        self.embeddings = OpenAIEmbeddings(
            model=Config.EMBEDDING_MODEL,
            openai_api_key=Config.OPENAI_API_KEY
        )
        
        # ChromaDB ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” (ì£¼ì‹ ì •ë³´)
        self.vectorstore = Chroma(
            collection_name=Config.CHROMA_COLLECTION_NAME,
            embedding_function=self.embeddings,
            persist_directory=Config.CHROMA_DB_PATH,
            collection_metadata={"hnsw:space": "cosine"}
        )
        
        # ë‰´ìŠ¤ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
        self.news_vectorstore = Chroma(
            collection_name=Config.CHROMA_NEWS_COLLECTION_NAME,
            embedding_function=self.embeddings,
            persist_directory=Config.CHROMA_DB_PATH,
            collection_metadata={"hnsw:space": "cosine"}
        )
        
        # ì£¼ì‹ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¡œë“œ
        if self.vectorstore._collection.count() == 0:
            print("ğŸ“Š ì£¼ì‹ ë°ì´í„° ë¡œë”© ì¤‘...")
            self._load_stock_data()
        else:
            print(f"âœ… ê¸°ì¡´ ì£¼ì‹ Vector DB ë¡œë“œ ì™„ë£Œ (ì´ {self.vectorstore._collection.count()}ê°œ ì¢…ëª©)")
        
        # ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¡œë“œ
        if self.news_vectorstore._collection.count() == 0:
            print("ğŸ“° ë‰´ìŠ¤ ë°ì´í„° ë¡œë”© ì¤‘...")
            self._load_news_data()
        else:
            print(f"âœ… ê¸°ì¡´ ë‰´ìŠ¤ Vector DB ë¡œë“œ ì™„ë£Œ (ì´ {self.news_vectorstore._collection.count()}ê°œ ë‰´ìŠ¤)")
        
        VectorStoreService._initialized = True
    
    def _load_stock_data(self):
        """ì£¼ì‹ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ ë²¡í„° DB êµ¬ì¶•"""
        stock_data_path = Config.STOCK_DATA_PATH
        
        if not os.path.exists(stock_data_path):
            raise FileNotFoundError(f"Stock data file not found: {stock_data_path}")
        
        with open(stock_data_path, "r", encoding="utf-8") as f:
            stock_texts = json.load(f)
        
        texts = []
        metadatas = []
        
        for item in stock_texts:
            tags = item.get("tags", [])
            
            # ì¢…ëª© ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
            combined_content = f"""ì¢…ëª©ëª…: {item['name']}
ì‚°ì—…: {item['industry']}
ì„¤ëª…: {item['description']}
ì„¸ë¶€ë‚´ìš©: {' '.join(item['comments'])}
ì—°ê´€í‚¤ì›Œë“œ: {', '.join(tags)}
""".strip()
            
            texts.append(combined_content)
            
            metadatas.append({
                "market": item['market'],
                "code": item['code'],
                "name": item['name'],
                "industry": item['industry'],
            })
        
        # ë²¡í„° DBì— ì¶”ê°€
        self.vectorstore.add_texts(texts=texts, metadatas=metadatas)
        print(f"âœ… Vector DB êµ¬ì¶• ì™„ë£Œ! (ì´ {len(texts)}ê°œ ì¢…ëª©)")
    
    def _load_news_data(self):
        """ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ ë²¡í„° DB êµ¬ì¶• (ë°°ì¹˜ ì²˜ë¦¬)"""
        import time
        
        news_data_path = Config.NEWS_DATA_PATH
        
        if not os.path.exists(news_data_path):
            print(f"âš ï¸ ë‰´ìŠ¤ ë°ì´í„° íŒŒì¼ ì—†ìŒ: {news_data_path}")
            return
        
        with open(news_data_path, "r", encoding="utf-8") as f:
            news_list = json.load(f)
        
        print(f"ğŸ“° ì´ {len(news_list)}ê°œ ë‰´ìŠ¤ ë¡œë”© ì‹œì‘ (ë°°ì¹˜ ì²˜ë¦¬)...")
        
        # ë°°ì¹˜ í¬ê¸° ì„¤ì • (rate limit ê³ ë ¤)
        batch_size = 100
        total_batches = (len(news_list) + batch_size - 1) // batch_size
        
        for batch_idx in range(0, len(news_list), batch_size):
            batch_news = news_list[batch_idx:batch_idx + batch_size]
            
            texts = []
            metadatas = []
            
            for item in batch_news:
                # ë‰´ìŠ¤ ì œëª©ê³¼ ë‚´ìš©ì„ ê²°í•©í•˜ì—¬ ì„ë² ë”©
                # contentëŠ” 100ìë¡œ ì œí•œí•˜ì—¬ í† í° ì ˆì•½
                content_preview = item['content'][:100] + "..." if len(item['content']) > 100 else item['content']
                
                combined_content = f"""ì œëª©: {item['title']}
ë‚´ìš©: {content_preview}
ì¢…ëª©: {item['name']}
""".strip()
                
                texts.append(combined_content)
                
                metadatas.append({
                    "code": item['code'],
                    "name": item['name'],
                    "title": item['title'],
                    "content": content_preview,
                    "link": item['link'],
                    "published_date": item['published_date']
                })
            
            # ë²¡í„° DBì— ì¶”ê°€
            current_batch = batch_idx // batch_size + 1
            print(f"   ë°°ì¹˜ {current_batch}/{total_batches} ì²˜ë¦¬ ì¤‘... ({len(texts)}ê°œ ë‰´ìŠ¤)")
            
            try:
                self.news_vectorstore.add_texts(texts=texts, metadatas=metadatas)
                
                # Rate limit ë°©ì§€ë¥¼ ìœ„í•´ ëŒ€ê¸° (ë§ˆì§€ë§‰ ë°°ì¹˜ëŠ” ì œì™¸)
                if batch_idx + batch_size < len(news_list):
                    time.sleep(2)
                    
            except Exception as e:
                print(f"   âš ï¸ ë°°ì¹˜ {current_batch} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                print(f"   20ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                time.sleep(20)
                # ì¬ì‹œë„
                try:
                    self.news_vectorstore.add_texts(texts=texts, metadatas=metadatas)
                except Exception as retry_error:
                    print(f"   âŒ ì¬ì‹œë„ ì‹¤íŒ¨: {retry_error}")
                    print(f"   ë°°ì¹˜ {current_batch} ê±´ë„ˆëœ€")
                    continue
        
        total_loaded = self.news_vectorstore._collection.count()
        print(f"âœ… ë‰´ìŠ¤ Vector DB êµ¬ì¶• ì™„ë£Œ! (ì´ {total_loaded}ê°œ ë‰´ìŠ¤)")
    
    def similarity_search_with_score(
        self, 
        query: str, 
        k: int = 10
    ) -> List[Tuple[Document, float]]:
        """
        ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰ (ì£¼ì‹ ì •ë³´)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜
            
        Returns:
            (Document, distance) íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸
        """
        return self.vectorstore.similarity_search_with_score(query, k=k)
    
    def search_news_by_keyword(
        self, 
        query: str, 
        k: int = 5
    ) -> List[Tuple[Document, float]]:
        """
        í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ í‚¤ì›Œë“œ
            k: ë°˜í™˜í•  ë‰´ìŠ¤ ê°œìˆ˜
            
        Returns:
            (Document, distance) íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸
        """
        return self.news_vectorstore.similarity_search_with_score(query, k=k)
    
    def search_news_by_stock_code(
        self, 
        stock_code: str, 
        k: int = 5
    ) -> List[Dict]:
        """
        ì¢…ëª© ì½”ë“œë¡œ ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰
        
        Args:
            stock_code: ì¢…ëª© ì½”ë“œ
            k: ë°˜í™˜í•  ë‰´ìŠ¤ ê°œìˆ˜
            
        Returns:
            ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ (ë©”íƒ€ë°ì´í„°)
        """
        # ChromaDBì˜ where í•„í„° ì‚¬ìš©
        results = self.news_vectorstore._collection.get(
            where={"code": stock_code},
            limit=k
        )
        
        # ë©”íƒ€ë°ì´í„°ë§Œ ì¶”ì¶œ (contentëŠ” ì´ë¯¸ 100ìë¡œ ì œí•œë¨)
        news_list = []
        if results and results.get('metadatas'):
            for metadata in results['metadatas']:
                news_list.append({
                    "title": metadata.get('title', ''),
                    "content": metadata.get('content', ''),
                    "link": metadata.get('link', ''),
                    "published_date": metadata.get('published_date', '')
                })
        
        return news_list
